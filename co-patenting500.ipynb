{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network visualization\n",
    "\n",
    "This project attempts to create a network of collaboration among patent holders with more than 500 patents, using OECD HAN and European Patent Office's PATSTAT databases.\n",
    "\n",
    "link to gitHub repository:\n",
    "https://github.com/UOA-MEDSCI-736/dvasques83-medsci736\n",
    "\n",
    "- Obs: include invalid input statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import necessary modules\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import xlwt\n",
    "import csv\n",
    "from itertools import izip_longest\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import psycopg2 as pg\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function to get the data and return array with data\n",
    "def query_han_patents():  \n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    #CONNECT TO POSTGRESQL\n",
    "    connection_string = \"host= 'localhost' dbname='postgres' user='postgres' password=''\"\n",
    "    conn = pg.connect(connection_string)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    #Patent Number\n",
    "    patent_nbr_query = \"SELECT patent_number FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(patent_nbr_query)\n",
    "    patent_nbr_list = cur.fetchall()\n",
    "    #print 'The length of patents list is: ' + str(len(patent_nbr_list))\n",
    "    \n",
    "    #HAN ID\n",
    "    han_id_query = \"SELECT han_id FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(han_id_query)\n",
    "    han_id_list = cur.fetchall()\n",
    "    #print 'The length of han id list is: ' + str(len(han_id_list))\n",
    "    \n",
    "    #Clean name\n",
    "    clean_name_query = \"SELECT clean_name FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(clean_name_query)\n",
    "    clean_name_list = cur.fetchall()\n",
    "    #print 'The length of clean name list is: ' + str(len(clean_name_list))\n",
    "\n",
    "    #Country code\n",
    "    ctry_code_query = \"SELECT ctry_code FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(ctry_code_query)\n",
    "    ctry_code_list = cur.fetchall()\n",
    "    #print 'The length of country code list is: ' + str(len(ctry_code_list))\n",
    "    \n",
    "    #IPC\n",
    "    ipc_query = \"SELECT ipc FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(ipc_query)\n",
    "    ipc_list = cur.fetchall()\n",
    "    #print 'The length of IPC list is: ' + str(len(ipc_list))\n",
    "    \n",
    "    #Application year\n",
    "    app_year_query = \"SELECT app_year FROM final201602.pat_name_ctry_ipc_year\"\n",
    "    cur.execute(app_year_query)\n",
    "    app_year_list = cur.fetchall()\n",
    "    #print 'The length of application year list is: ' + str(len(app_year_list))\n",
    "    \n",
    "    appln_pathan_array = np.column_stack((patent_nbr_list, han_id_list, clean_name_list, ctry_code_list, ipc_list, app_year_list))\n",
    "    \n",
    "    print 'Running time to query: ' + str(time.time() - t0)\n",
    "    \n",
    "    cur.close()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return appln_pathan_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unique_array():\n",
    "    \n",
    "    appln_pathan_array = query_han_patents()\n",
    "    \n",
    "    df = pd.DataFrame(data=appln_pathan_array, columns=['patent number','han_id','name','country','ipc code','year'])\n",
    "    df_unique = df.drop_duplicates()\n",
    "    \n",
    "    patent_number = df_unique['patent number'].values.tolist()\n",
    "    han_id = df_unique['han_id'].values.tolist()\n",
    "    name = df_unique['name'].values.tolist()\n",
    "    country = df_unique['country'].values.tolist()\n",
    "    ipc = df_unique['ipc code'].values.tolist()\n",
    "    year = df_unique['year'].values.tolist()\n",
    "    \n",
    "    data = np.column_stack((patent_number, han_id, name, country, ipc, year))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_network(appln_pathan_array):\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #CREATE NETWORK\n",
    "    B = nx.Graph()\n",
    "    for patent in appln_pathan_array:\n",
    "        B.add_node(patent[0], bipartite=0, year=patent[5])\n",
    "        B.add_node(patent[1], bipartite=1, name=str(patent[2]), ctry=str(patent[3]))\n",
    "        B.add_edge(patent[0], patent[1])\n",
    "\n",
    "    print 'Running time to create bipartite innovation network: ' + str(time.time() - t0)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def more500_bipnetwork(B):\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    #data = unique_array()\n",
    "    #B = create_network(data)\n",
    "    \n",
    "    top_nodes = set(node for node,d in B.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "    bottom_nodes = set(B) - top_nodes #klist\n",
    "    #deg_top, deg_bottom = bipartite.degrees(B,bottom_nodes) #dictionary\n",
    "    \n",
    "    B500 = B.copy()\n",
    "    \n",
    "    for node in bottom_nodes:\n",
    "        if B.degree(node) < 501:\n",
    "            B500.remove_node(node)\n",
    "            \n",
    "    top_nodes = set(node for node,d in B500.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "    bottom_nodes = set(B500) - top_nodes #klist \n",
    "    \n",
    "    print 'Running time to create bipartite innovation network - 500: ' + str(time.time() - t0)\n",
    "    \n",
    "    return B500, top_nodes, bottom_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#projected network of companies with more than 500 patents\n",
    "\n",
    "def more500_copatenting(B500):\n",
    "    \n",
    "    t0 = time.time()\n",
    "\n",
    "    #BIPARTITE NETWORK        \n",
    "    top_nodes = set(node for node,d in B500.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "    bottom_nodes = set(B500) - top_nodes #klist\n",
    "    deg_top, deg_bottom = bipartite.degrees(B,bottom_nodes) #dictionary\n",
    "    \n",
    "           \n",
    "    #WEIGHTED PROJECTED NETWORK\n",
    "    G_w = bipartite.weighted_projected_graph(B500,bottom_nodes)\n",
    "    \n",
    "    print 'Running time to create projected collaboration network - 500: ' + str(time.time() - t0)\n",
    "    \n",
    "    return G_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create bipartite network with patents as top nodes (code 0) and applicants as bottom nodes (code 1)\n",
    "#patents have attributes year and ipc\n",
    "#applicants have attributes name, country, year and ipc\n",
    "\n",
    "def create_network(appln_pathan_array):\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    #CREATE NETWORK\n",
    "    B = nx.Graph()\n",
    "    t = 0\n",
    "    \n",
    "    for record in appln_pathan_array:\n",
    "        if record[0] in B.nodes():\n",
    "            B.node[record[0]]['ipc'].append(record[4])\n",
    "        else:\n",
    "            B.add_node(record[0], bipartite=0, year=record[5], ipc=[record[4]])\n",
    "            \n",
    "        if record[1] in B.nodes():\n",
    "            B.node[record[1]]['year'].append(record[5])\n",
    "            B.node[record[1]]['ipc'].append(record[4])\n",
    "        else:    \n",
    "            B.add_node(record[1], bipartite=1, name=str(record[2]), ctry=str(record[3]), year=[record[5]], ipc=[record[4]])\n",
    "            \n",
    "        #if (record[0], record[1]) not in B.edges():    \n",
    "        B.add_edge(record[0], record[1])\n",
    "        t += 1\n",
    "        if t % 1000 == 0:\n",
    "            print t\n",
    "\n",
    "    print 'Running time to create network: ' + str(time.time() - t0)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time to query: 64.7629959583\n",
      "Running time to create bipartite innovation network: 62.7017679214\n"
     ]
    }
   ],
   "source": [
    "data = unique_array()\n",
    "B = create_network(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time to create bipartite innovation network - 500: 107.528404951\n"
     ]
    }
   ],
   "source": [
    "B2, top_nodes, bottom_nodes = more500_bipnetwork(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time to create projected collaboration network - 500: 24.7157599926\n"
     ]
    }
   ],
   "source": [
    "G_w = more500_copatenting(B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Create a json file with node and link information from pandas unique dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#jsonfile = open(\"co-patenting500.json\", \"wb\")\n",
    "\n",
    "#create nodes\n",
    "#print >> jsonfile, \"{\"\n",
    "#print >> jsonfile, '\"nodes\": ['\n",
    "\n",
    "\n",
    "nodes = []\n",
    "for node in bottom_nodes:\n",
    "    json_node = {\n",
    "        \"id\": str(B2.node[node]['name']),\n",
    "        \"group\": str(B2.node[node]['ctry']),\n",
    "        \"bipdegree\": str(B2.degree(node)),\n",
    "        \"projdegree\": str(G_w.degree(node))\n",
    "    }\n",
    "    nodes.append(json_node)\n",
    "    \n",
    "links = []\n",
    "for link in G_w.edges(data=True):\n",
    "    json_link = {\n",
    "        \"source\": str(B2.node[link[0]]['name']),\n",
    "        \"target\": str(B2.node[link[1]]['name']),\n",
    "        \"value\": str(link[2]['weight'])\n",
    "    }\n",
    "    links.append(json_link)\n",
    "    \n",
    "output = {\n",
    "    \"nodes\": nodes,\n",
    "    \"links\": links\n",
    "}\n",
    "\n",
    "with open('co-patenting500.json', 'wb') as jsonfile:\n",
    "    json.dump(output,jsonfile, indent=2)\n",
    "    \n",
    "#json_string = json.dumps(output)\n",
    "\n",
    "#print >> jsonfile, json_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print type(G_w.edges(data=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "for node in bottom_nodes:\n",
    "    print >> jsonfile, '{\"id\": '+'\"'+str(B.node[node]['name'])+'\"'+', '+\\\n",
    "                        '\"group\": '+'\"'+str(B.node[node]['ctry'])+'\"'+', '+\\\n",
    "                        '\"bipdegree\": '+str(B.degree(node))+', '\\\n",
    "                        '\"projdegree\": '+str(G_w.degree(node))+'},'\n",
    "\n",
    "print >> jsonfile, '],'\n",
    "\n",
    "#create links\n",
    "print >> jsonfile, '\"links\": ['\n",
    "\n",
    "for link in G_w.edges(data=True):\n",
    "    print >> jsonfile, '{\"source\": '+'\"'+str(B.node[link[0]]['name'])+'\"'+', '+\\\n",
    "                        '\"target\": '+'\"'+str(B.node[link[1]]['name'])+'\"'+', '+\\\n",
    "                        '\"value\": '+str(link[2]['weight'])+'},'\n",
    "            \n",
    "print >> jsonfile, '],'\n",
    "print >> jsonfile, '}'\n",
    "jsonfile.close()             \n",
    "    \n",
    "#jsonfile.write('\\n,')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_nodes = set(node for node,d in B.nodes(data=True) if d['bipartite']==0) #dlist\n",
    "bottom_nodes = set(B) - top_nodes #klist\n",
    "deg_top, deg_bottom = bipartite.degrees(B,bottom_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted_deg_bottom = sorted(deg_bottom.items(), key=operator.itemgetter(1))\n",
    "top30_applicants = sorted_deg_bottom[-30:]\n",
    "sortedtop30 = reversed(top30_applicants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print reversed(sorted_deg_bottom[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degrees = deg_bottom.values()\n",
    "sort = sorted(degrees, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sort[:100]\n",
    "print sum(sort[:100])\n",
    "print sum(sort[:100])/float(sum(sort))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
